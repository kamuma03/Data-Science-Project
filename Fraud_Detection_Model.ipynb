{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fraud Detection Model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRemISVIyVCShtv+6anNuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamuma03/Fraud-Detection-Project/blob/main/Fraud_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7aCYnEQXsQJ",
        "outputId": "953ae5f8-5885-453a-e709-26b70e29a168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\r\u001b[K     |██                              | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Collecting scikit-learn>=0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.16.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.7.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWmomRRi3Onk"
      },
      "source": [
        "## Import of the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAH5NSDy2RGB"
      },
      "source": [
        "# Import of all the required libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import mean_squared_error, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import imblearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEjs6k5s3Xg7"
      },
      "source": [
        "## Import of the Dataset\n",
        "\n",
        "The data will be imported from a pickle file saved after the data analysis notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epYJFijk3Sik",
        "outputId": "e2a1784a-9eb8-485a-8c01-1ee6a6ab1ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Connecting the Google drive with Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPCBjteh3LEK",
        "outputId": "198f2307-6614-4214-f0b2-de06c6ccf0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "# Import of the train and test datasets into the Panda dataframe from Google drive \n",
        "# To load data from the local drive the location below can be changed accordingly\n",
        "\n",
        "\n",
        "train_df = pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/train_df_final.pkl\", \"rb\"))\n",
        "test_df = pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/test_df_final.pkl\", \"rb\"))\n",
        "\n",
        "train_df\n",
        "test_df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V16</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V24</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.584007</td>\n",
              "      <td>0.001509</td>\n",
              "      <td>0.292260</td>\n",
              "      <td>1.120755</td>\n",
              "      <td>-0.166826</td>\n",
              "      <td>-0.501695</td>\n",
              "      <td>-0.694423</td>\n",
              "      <td>-0.276469</td>\n",
              "      <td>0.284019</td>\n",
              "      <td>0.265888</td>\n",
              "      <td>-0.106804</td>\n",
              "      <td>0.167209</td>\n",
              "      <td>0.361133</td>\n",
              "      <td>0.375231</td>\n",
              "      <td>0.102098</td>\n",
              "      <td>0.144502</td>\n",
              "      <td>42.81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.326714</td>\n",
              "      <td>-0.979830</td>\n",
              "      <td>-0.625116</td>\n",
              "      <td>-0.636415</td>\n",
              "      <td>0.050208</td>\n",
              "      <td>-0.785860</td>\n",
              "      <td>0.815473</td>\n",
              "      <td>-1.025594</td>\n",
              "      <td>0.271240</td>\n",
              "      <td>1.751346</td>\n",
              "      <td>0.164916</td>\n",
              "      <td>0.109578</td>\n",
              "      <td>-0.011447</td>\n",
              "      <td>-0.859332</td>\n",
              "      <td>-0.021529</td>\n",
              "      <td>0.003230</td>\n",
              "      <td>75.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.097691</td>\n",
              "      <td>-0.011746</td>\n",
              "      <td>0.597501</td>\n",
              "      <td>0.130716</td>\n",
              "      <td>-0.174237</td>\n",
              "      <td>0.383371</td>\n",
              "      <td>0.171848</td>\n",
              "      <td>0.344720</td>\n",
              "      <td>0.589561</td>\n",
              "      <td>0.230686</td>\n",
              "      <td>-0.192933</td>\n",
              "      <td>0.233496</td>\n",
              "      <td>0.825427</td>\n",
              "      <td>-1.115397</td>\n",
              "      <td>-0.020643</td>\n",
              "      <td>-0.079921</td>\n",
              "      <td>2.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.593912</td>\n",
              "      <td>-0.236255</td>\n",
              "      <td>-0.002224</td>\n",
              "      <td>-0.392776</td>\n",
              "      <td>-2.005520</td>\n",
              "      <td>-0.306309</td>\n",
              "      <td>-0.253465</td>\n",
              "      <td>1.539975</td>\n",
              "      <td>-0.407657</td>\n",
              "      <td>0.687552</td>\n",
              "      <td>-0.258684</td>\n",
              "      <td>1.995801</td>\n",
              "      <td>-1.554302</td>\n",
              "      <td>-0.531345</td>\n",
              "      <td>0.346683</td>\n",
              "      <td>0.104860</td>\n",
              "      <td>8.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.863194</td>\n",
              "      <td>3.853830</td>\n",
              "      <td>0.220877</td>\n",
              "      <td>-0.296455</td>\n",
              "      <td>0.207090</td>\n",
              "      <td>-0.487512</td>\n",
              "      <td>1.454433</td>\n",
              "      <td>-0.153871</td>\n",
              "      <td>-0.147691</td>\n",
              "      <td>0.606259</td>\n",
              "      <td>-0.311545</td>\n",
              "      <td>0.118870</td>\n",
              "      <td>0.611417</td>\n",
              "      <td>-0.387779</td>\n",
              "      <td>-0.003506</td>\n",
              "      <td>-0.061238</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85439</th>\n",
              "      <td>-0.753070</td>\n",
              "      <td>-1.448546</td>\n",
              "      <td>1.130943</td>\n",
              "      <td>1.167232</td>\n",
              "      <td>0.201294</td>\n",
              "      <td>-0.245013</td>\n",
              "      <td>0.113600</td>\n",
              "      <td>-1.027914</td>\n",
              "      <td>1.212622</td>\n",
              "      <td>-0.053734</td>\n",
              "      <td>0.050720</td>\n",
              "      <td>0.202703</td>\n",
              "      <td>0.725051</td>\n",
              "      <td>-1.016408</td>\n",
              "      <td>0.469657</td>\n",
              "      <td>0.304103</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85440</th>\n",
              "      <td>-0.539994</td>\n",
              "      <td>0.514863</td>\n",
              "      <td>-0.043655</td>\n",
              "      <td>0.851781</td>\n",
              "      <td>-0.059080</td>\n",
              "      <td>0.319422</td>\n",
              "      <td>-0.573884</td>\n",
              "      <td>-1.541622</td>\n",
              "      <td>-0.192496</td>\n",
              "      <td>-0.702496</td>\n",
              "      <td>-0.173193</td>\n",
              "      <td>0.059047</td>\n",
              "      <td>0.441880</td>\n",
              "      <td>0.574042</td>\n",
              "      <td>-0.007875</td>\n",
              "      <td>-0.067811</td>\n",
              "      <td>40.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85441</th>\n",
              "      <td>-1.833594</td>\n",
              "      <td>-1.464593</td>\n",
              "      <td>-0.448623</td>\n",
              "      <td>-0.496368</td>\n",
              "      <td>0.481275</td>\n",
              "      <td>-1.151529</td>\n",
              "      <td>-0.210526</td>\n",
              "      <td>0.895314</td>\n",
              "      <td>-0.274270</td>\n",
              "      <td>1.832300</td>\n",
              "      <td>0.754963</td>\n",
              "      <td>0.363656</td>\n",
              "      <td>0.279139</td>\n",
              "      <td>-0.118669</td>\n",
              "      <td>0.209083</td>\n",
              "      <td>-0.049870</td>\n",
              "      <td>140.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85442</th>\n",
              "      <td>1.373911</td>\n",
              "      <td>1.057884</td>\n",
              "      <td>-0.413288</td>\n",
              "      <td>0.412863</td>\n",
              "      <td>-0.382925</td>\n",
              "      <td>0.640802</td>\n",
              "      <td>-0.550427</td>\n",
              "      <td>0.595095</td>\n",
              "      <td>-1.184722</td>\n",
              "      <td>0.375467</td>\n",
              "      <td>0.537641</td>\n",
              "      <td>0.470784</td>\n",
              "      <td>0.868639</td>\n",
              "      <td>0.059266</td>\n",
              "      <td>-0.086933</td>\n",
              "      <td>0.025684</td>\n",
              "      <td>343.39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85443</th>\n",
              "      <td>-1.683357</td>\n",
              "      <td>-0.827478</td>\n",
              "      <td>-0.431862</td>\n",
              "      <td>-0.102517</td>\n",
              "      <td>-0.114782</td>\n",
              "      <td>0.349091</td>\n",
              "      <td>-0.069912</td>\n",
              "      <td>-1.516944</td>\n",
              "      <td>0.405564</td>\n",
              "      <td>0.224752</td>\n",
              "      <td>-0.063979</td>\n",
              "      <td>0.558429</td>\n",
              "      <td>-0.712699</td>\n",
              "      <td>-0.010307</td>\n",
              "      <td>0.392933</td>\n",
              "      <td>0.213428</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>85443 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             V1        V4        V5  ...       V28  Amount  Class\n",
              "Id                                   ...                         \n",
              "1     -0.584007  0.001509  0.292260  ...  0.144502   42.81      0\n",
              "2      1.326714 -0.979830 -0.625116  ...  0.003230   75.00      0\n",
              "3      2.097691 -0.011746  0.597501  ... -0.079921    2.29      0\n",
              "4     -1.593912 -0.236255 -0.002224  ...  0.104860    8.99      0\n",
              "5      1.863194  3.853830  0.220877  ... -0.061238    0.00      0\n",
              "...         ...       ...       ...  ...       ...     ...    ...\n",
              "85439 -0.753070 -1.448546  1.130943  ...  0.304103    0.75      0\n",
              "85440 -0.539994  0.514863 -0.043655  ... -0.067811   40.00      0\n",
              "85441 -1.833594 -1.464593 -0.448623  ... -0.049870  140.00      0\n",
              "85442  1.373911  1.057884 -0.413288  ...  0.025684  343.39      0\n",
              "85443 -1.683357 -0.827478 -0.431862  ...  0.213428    5.00      0\n",
              "\n",
              "[85443 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob0M2T_R51W8"
      },
      "source": [
        "## Unbalance Dataset Approaches\n",
        "\n",
        "Reference:\n",
        "1. https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/#:~:text=Imbalanced%20data%20typically%20refers%20to,with%20100%20instances%20(rows).\n",
        "\n",
        "2. https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets/notebook\n",
        "\n",
        "\n",
        "Below there are the approaches\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY7EKEnZOhRg"
      },
      "source": [
        "### 1. Model with Different Algorithms\n",
        "Create the model with two different algorithms to see the performance with the data as it is\n",
        "\n",
        "  Will evaluate the models with MSE and F1 score\n",
        "\n",
        "  The model tested will be random forrest and SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Bqte_g56-T",
        "outputId": "5b0003fd-320f-40cd-d7b2-0060ac38b11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "# Dividing the training set in training and validation\n",
        "\n",
        "train_set, validation_set = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "validation_set"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V16</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V24</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>133885</th>\n",
              "      <td>1.940198</td>\n",
              "      <td>-0.101637</td>\n",
              "      <td>0.069030</td>\n",
              "      <td>-0.540231</td>\n",
              "      <td>0.177363</td>\n",
              "      <td>0.806425</td>\n",
              "      <td>0.135101</td>\n",
              "      <td>0.347050</td>\n",
              "      <td>0.055140</td>\n",
              "      <td>0.950588</td>\n",
              "      <td>0.004504</td>\n",
              "      <td>-0.252833</td>\n",
              "      <td>-0.816292</td>\n",
              "      <td>-0.357979</td>\n",
              "      <td>-0.059435</td>\n",
              "      <td>-0.047633</td>\n",
              "      <td>63.94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154103</th>\n",
              "      <td>1.943954</td>\n",
              "      <td>-0.650764</td>\n",
              "      <td>-1.272188</td>\n",
              "      <td>-1.544799</td>\n",
              "      <td>0.233190</td>\n",
              "      <td>1.061826</td>\n",
              "      <td>0.398137</td>\n",
              "      <td>0.825185</td>\n",
              "      <td>-1.451797</td>\n",
              "      <td>1.029520</td>\n",
              "      <td>0.249749</td>\n",
              "      <td>0.142529</td>\n",
              "      <td>0.508749</td>\n",
              "      <td>0.091523</td>\n",
              "      <td>0.042885</td>\n",
              "      <td>-0.017094</td>\n",
              "      <td>116.43</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167775</th>\n",
              "      <td>1.904386</td>\n",
              "      <td>-1.078358</td>\n",
              "      <td>-0.180539</td>\n",
              "      <td>-1.037596</td>\n",
              "      <td>0.385718</td>\n",
              "      <td>-0.227687</td>\n",
              "      <td>0.623200</td>\n",
              "      <td>1.089863</td>\n",
              "      <td>-0.463918</td>\n",
              "      <td>0.384421</td>\n",
              "      <td>0.081591</td>\n",
              "      <td>-0.069953</td>\n",
              "      <td>-0.144715</td>\n",
              "      <td>-1.635851</td>\n",
              "      <td>0.048465</td>\n",
              "      <td>-0.056774</td>\n",
              "      <td>76.05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173612</th>\n",
              "      <td>2.094920</td>\n",
              "      <td>0.325489</td>\n",
              "      <td>0.323692</td>\n",
              "      <td>-0.040390</td>\n",
              "      <td>-0.253578</td>\n",
              "      <td>2.260892</td>\n",
              "      <td>-0.437862</td>\n",
              "      <td>0.385009</td>\n",
              "      <td>2.168176</td>\n",
              "      <td>-0.204619</td>\n",
              "      <td>-0.353913</td>\n",
              "      <td>0.085156</td>\n",
              "      <td>0.582884</td>\n",
              "      <td>0.339348</td>\n",
              "      <td>-0.029217</td>\n",
              "      <td>-0.059727</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178897</th>\n",
              "      <td>-1.099180</td>\n",
              "      <td>0.905753</td>\n",
              "      <td>0.410698</td>\n",
              "      <td>0.537857</td>\n",
              "      <td>0.620574</td>\n",
              "      <td>-0.817007</td>\n",
              "      <td>-0.192094</td>\n",
              "      <td>1.203643</td>\n",
              "      <td>0.171853</td>\n",
              "      <td>-0.534837</td>\n",
              "      <td>0.144607</td>\n",
              "      <td>-0.041665</td>\n",
              "      <td>0.138225</td>\n",
              "      <td>-1.299114</td>\n",
              "      <td>0.186094</td>\n",
              "      <td>0.051719</td>\n",
              "      <td>91.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50508</th>\n",
              "      <td>1.733548</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>1.181809</td>\n",
              "      <td>-0.141513</td>\n",
              "      <td>0.376332</td>\n",
              "      <td>0.733783</td>\n",
              "      <td>-0.858369</td>\n",
              "      <td>0.200218</td>\n",
              "      <td>-1.266236</td>\n",
              "      <td>-0.472904</td>\n",
              "      <td>-0.010768</td>\n",
              "      <td>-0.106158</td>\n",
              "      <td>-0.196092</td>\n",
              "      <td>-1.047865</td>\n",
              "      <td>0.018342</td>\n",
              "      <td>-0.025503</td>\n",
              "      <td>100.94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20727</th>\n",
              "      <td>-1.101104</td>\n",
              "      <td>-1.579081</td>\n",
              "      <td>-0.568099</td>\n",
              "      <td>-1.099471</td>\n",
              "      <td>0.334310</td>\n",
              "      <td>-0.922823</td>\n",
              "      <td>0.106619</td>\n",
              "      <td>-0.204892</td>\n",
              "      <td>-0.446006</td>\n",
              "      <td>1.994289</td>\n",
              "      <td>0.300301</td>\n",
              "      <td>0.653571</td>\n",
              "      <td>1.456416</td>\n",
              "      <td>0.551542</td>\n",
              "      <td>0.084508</td>\n",
              "      <td>0.125097</td>\n",
              "      <td>24.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128437</th>\n",
              "      <td>-2.980376</td>\n",
              "      <td>-0.576047</td>\n",
              "      <td>1.451763</td>\n",
              "      <td>0.036765</td>\n",
              "      <td>-2.144803</td>\n",
              "      <td>3.300633</td>\n",
              "      <td>1.429805</td>\n",
              "      <td>1.950226</td>\n",
              "      <td>0.190237</td>\n",
              "      <td>-0.467380</td>\n",
              "      <td>-0.739158</td>\n",
              "      <td>0.507472</td>\n",
              "      <td>-1.136045</td>\n",
              "      <td>-0.466431</td>\n",
              "      <td>0.955296</td>\n",
              "      <td>0.197942</td>\n",
              "      <td>93.96</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166738</th>\n",
              "      <td>-0.504682</td>\n",
              "      <td>0.286529</td>\n",
              "      <td>0.647267</td>\n",
              "      <td>1.143388</td>\n",
              "      <td>0.647575</td>\n",
              "      <td>-1.049391</td>\n",
              "      <td>-0.917402</td>\n",
              "      <td>-1.881718</td>\n",
              "      <td>0.569023</td>\n",
              "      <td>0.648177</td>\n",
              "      <td>-0.530864</td>\n",
              "      <td>0.278936</td>\n",
              "      <td>0.443661</td>\n",
              "      <td>0.129440</td>\n",
              "      <td>-0.233368</td>\n",
              "      <td>-0.048067</td>\n",
              "      <td>119.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53742</th>\n",
              "      <td>2.274293</td>\n",
              "      <td>-1.351831</td>\n",
              "      <td>0.747265</td>\n",
              "      <td>0.119866</td>\n",
              "      <td>-0.317891</td>\n",
              "      <td>-1.200849</td>\n",
              "      <td>1.076282</td>\n",
              "      <td>0.286860</td>\n",
              "      <td>0.477945</td>\n",
              "      <td>0.891989</td>\n",
              "      <td>0.054519</td>\n",
              "      <td>0.342897</td>\n",
              "      <td>0.912797</td>\n",
              "      <td>-0.289242</td>\n",
              "      <td>-0.088138</td>\n",
              "      <td>-0.091976</td>\n",
              "      <td>29.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39748 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              V1        V4        V5  ...       V28  Amount  Class\n",
              "Id                                    ...                         \n",
              "133885  1.940198 -0.101637  0.069030  ... -0.047633   63.94      0\n",
              "154103  1.943954 -0.650764 -1.272188  ... -0.017094  116.43      0\n",
              "167775  1.904386 -1.078358 -0.180539  ... -0.056774   76.05      0\n",
              "173612  2.094920  0.325489  0.323692  ... -0.059727    1.00      0\n",
              "178897 -1.099180  0.905753  0.410698  ...  0.051719   91.69      0\n",
              "...          ...       ...       ...  ...       ...     ...    ...\n",
              "50508   1.733548  0.000954  1.181809  ... -0.025503  100.94      0\n",
              "20727  -1.101104 -1.579081 -0.568099  ...  0.125097   24.99      0\n",
              "128437 -2.980376 -0.576047  1.451763  ...  0.197942   93.96      0\n",
              "166738 -0.504682  0.286529  0.647267  ... -0.048067  119.99      0\n",
              "53742   2.274293 -1.351831  0.747265  ... -0.091976   29.50      0\n",
              "\n",
              "[39748 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqGs_2QQa5lt"
      },
      "source": [
        "# definition of the function to model and score the classification with the random forest\n",
        "def random_forest_classifier(test, validation):\n",
        "  x_test = test.loc[:, test.columns != 'Class']\n",
        "  y_test = test[\"Class\"]\n",
        "  x_val = validation.loc[:, validation.columns != 'Class']\n",
        "  y_val = validation[\"Class\"]\n",
        "  model= RandomForestClassifier(n_estimators=500, max_depth=400, max_samples=80000)\n",
        "  model.fit(x_test, y_test)\n",
        "\n",
        "  test_prediction = model.predict(x_test)\n",
        "  print(\"training set score \", model.score(x_test, y_test))\n",
        "  f1_score_test = f1_score(y_test, test_prediction)\n",
        "  print(\"F1 training set score \", f1_score_test)\n",
        "  mse_test = mean_squared_error(y_test, test_prediction)\n",
        "  print(\"MSE training set score \", mse_test)\n",
        "\n",
        "\n",
        "  validation_prediction = model.predict(x_val)\n",
        "  print(\"validation set score \", model.score(x_val, y_val))\n",
        "  f1_score_validation = f1_score(y_val, validation_prediction)\n",
        "  print(\"F1 training set score \", f1_score_validation)\n",
        "  mse_validation = mean_squared_error(y_val, validation_prediction)\n",
        "  print(\"MSE training set score \", mse_validation)\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV4QC2Smf0VM",
        "outputId": "83e97c90-a53f-466b-b5e3-ab72b371836e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_1 = random_forest_classifier(train_set, validation_set)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.9996980904219186\n",
            "F1 training set score  0.9058823529411766\n",
            "MSE training set score  0.0003019095780813646\n",
            "validation set score  0.9994465130321022\n",
            "F1 training set score  0.835820895522388\n",
            "MSE training set score  0.0005534869678977558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI13aOoAgbnZ"
      },
      "source": [
        "# definition of the function to model and score the classification with the support vector machine\n",
        "def svm(test, validation):\n",
        "  x_test = test.loc[:, test.columns != 'Class']\n",
        "  y_test = test[\"Class\"]\n",
        "  x_val = validation.loc[:, validation.columns != 'Class']\n",
        "  y_val = validation[\"Class\"]\n",
        "  model= SVC(C=100000, kernel='rbf')\n",
        "  model.fit(x_test, y_test)\n",
        "  test_prediction = model.predict(x_test)\n",
        "  print(\"training set score \", model.score(x_test, y_test))\n",
        "  f1_score_test = f1_score(y_test, test_prediction)\n",
        "  print(\"F1 training set score \", f1_score_test)\n",
        "  mse_test = mean_squared_error(y_test, test_prediction)\n",
        "  print(\"MSE training set score \", mse_test)\n",
        "\n",
        "\n",
        "  validation_prediction = model.predict(x_val)\n",
        "  print(\"validation set score \", model.score(x_val, y_val))\n",
        "  f1_score_validation = f1_score(y_val, validation_prediction)\n",
        "  print(\"F1 training set score \", f1_score_validation)\n",
        "  mse_validation = mean_squared_error(y_val, validation_prediction)\n",
        "  print(\"MSE training set score \", mse_validation)\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg8q7Wkvg_58",
        "outputId": "0f905afc-2a5d-4a38-9502-5e5306d973ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_2 = svm(train_set, validation_set)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.9995597151986313\n",
            "F1 training set score  0.8638132295719845\n",
            "MSE training set score  0.00044028480136865675\n",
            "validation set score  0.9992704035423166\n",
            "F1 training set score  0.7786259541984732\n",
            "MSE training set score  0.0007295964576834055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KyLtQ9TOvO5"
      },
      "source": [
        "The above models have got F1 validation score of about 83% with random forest\n",
        "\n",
        "The hyper parameters for both models have been manually tweaked to have best result as shown above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJLsyu7xPJ0M"
      },
      "source": [
        "###2. Oversampling of the Dataset \n",
        "\n",
        "Using the Imbalance learn library to use various method to oversample\n",
        "\n",
        "Reference:\n",
        "\n",
        "https://github.com/scikit-learn-contrib/imbalanced-learn\n",
        "\n",
        "https://imbalanced-learn.org/stable/index.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWeoWF3qOuMW"
      },
      "source": [
        "# Oversampling of the dataset randomly \n",
        "\n",
        "def oversample_random(test):\n",
        "  x_test = test.loc[:, test.columns != 'Class']\n",
        "  y_test = test[\"Class\"]\n",
        "  oversampler = imblearn.over_sampling.RandomOverSampler(random_state=0)\n",
        "  new_x_test, new_y_test = oversampler.fit_resample(x_test, y_test)\n",
        "  df = new_x_test\n",
        "  df[\"Class\"] = new_y_test\n",
        "  return df\n",
        "\n",
        "oversample_train_set = oversample_random(train_set)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGT5My0WaMuQ",
        "outputId": "8f68f1d9-e79f-47ce-8315-d4bfcb632d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_3 = random_forest_classifier(oversample_train_set, validation_set)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.999949593598387\n",
            "F1 training set score  0.9999495961390643\n",
            "MSE training set score  5.0406401613004854e-05\n",
            "validation set score  0.999345879037939\n",
            "F1 training set score  0.8169014084507041\n",
            "MSE training set score  0.0006541209620609842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlVq9eWsaVEB"
      },
      "source": [
        "model_4 = svm(oversample_train_set, validation_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc7fhIWzg01g"
      },
      "source": [
        "# Oversampling of the dataset with smote algorithms and svm   \n",
        "\n",
        "def oversample_smote_svm(test):\n",
        "  x_test = test.loc[:, test.columns != 'Class']\n",
        "  y_test = test[\"Class\"]\n",
        "  oversampler = imblearn.over_sampling.SVMSMOTE(random_state=42)\n",
        "  new_x_test, new_y_test = oversampler.fit_resample(x_test, y_test)\n",
        "  df = new_x_test\n",
        "  df[\"Class\"] = new_y_test\n",
        "  return df\n",
        "\n",
        "oversample_svm_train_set = oversample_smote_svm(train_set)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw4eyUTvhlDS",
        "outputId": "af2895e0-9ee0-4b21-a75a-3c366bdbcdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_5 = random_forest_classifier(oversample_svm_train_set, validation_set)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.9998204271942537\n",
            "F1 training set score  0.9998204277599781\n",
            "MSE training set score  0.00017957280574632979\n",
            "validation set score  0.9992955620408575\n",
            "F1 training set score  0.8133333333333335\n",
            "MSE training set score  0.0007044379591425984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRvIrgFKhlZe"
      },
      "source": [
        "model_6 = svm(oversample_svm_train_set, validation_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY-8fLBSlVax"
      },
      "source": [
        "The result shows that the random sampling improves the F1 test set score to about 100% but the validation set F1 score is lower 81% than the base model 83%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6BaUsS-lVFc"
      },
      "source": [
        "### 3. Undersampling of the Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZJ-ZGXm3cWW"
      },
      "source": [
        "# undersampling of the dataset with Cluster Centroids \n",
        "\n",
        "def undersample_random(test):\n",
        "  x_test = test.loc[:, test.columns != 'Class']\n",
        "  y_test = test[\"Class\"]\n",
        "  undersampler = imblearn.under_sampling.ClusterCentroids(random_state=0)\n",
        "  new_x_test, new_y_test = undersampler.fit_resample(x_test, y_test)\n",
        "  df = new_x_test\n",
        "  df[\"Class\"] = new_y_test\n",
        "  return df\n",
        "\n",
        "undersample_random_train_set = undersample_random(train_set)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ap0dLL5Sy1",
        "outputId": "0db2ccf0-ab91-401f-d926-f01b306a2095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "undersample_random_train_set"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V16</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V24</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.529512</td>\n",
              "      <td>0.459757</td>\n",
              "      <td>-0.104006</td>\n",
              "      <td>-0.246517</td>\n",
              "      <td>0.020092</td>\n",
              "      <td>0.620889</td>\n",
              "      <td>-0.096285</td>\n",
              "      <td>-0.100765</td>\n",
              "      <td>0.086032</td>\n",
              "      <td>-0.164478</td>\n",
              "      <td>-0.160788</td>\n",
              "      <td>-0.061642</td>\n",
              "      <td>-0.035527</td>\n",
              "      <td>0.037715</td>\n",
              "      <td>-0.008093</td>\n",
              "      <td>-0.015416</td>\n",
              "      <td>28.912886</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.811613</td>\n",
              "      <td>0.523180</td>\n",
              "      <td>-2.822458</td>\n",
              "      <td>2.619627</td>\n",
              "      <td>-0.297742</td>\n",
              "      <td>-0.354216</td>\n",
              "      <td>-0.771714</td>\n",
              "      <td>-0.160478</td>\n",
              "      <td>0.185970</td>\n",
              "      <td>0.039664</td>\n",
              "      <td>1.490858</td>\n",
              "      <td>0.378613</td>\n",
              "      <td>-0.269425</td>\n",
              "      <td>-0.111635</td>\n",
              "      <td>-0.052501</td>\n",
              "      <td>-0.016139</td>\n",
              "      <td>1267.679388</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.619164</td>\n",
              "      <td>-0.031784</td>\n",
              "      <td>-0.726452</td>\n",
              "      <td>0.586349</td>\n",
              "      <td>-0.226553</td>\n",
              "      <td>0.039564</td>\n",
              "      <td>-0.289528</td>\n",
              "      <td>-0.054067</td>\n",
              "      <td>-0.015248</td>\n",
              "      <td>-0.269958</td>\n",
              "      <td>0.411423</td>\n",
              "      <td>0.191315</td>\n",
              "      <td>0.056655</td>\n",
              "      <td>-0.048664</td>\n",
              "      <td>-0.031753</td>\n",
              "      <td>0.036311</td>\n",
              "      <td>448.502095</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.675999</td>\n",
              "      <td>2.638208</td>\n",
              "      <td>-6.613113</td>\n",
              "      <td>7.938201</td>\n",
              "      <td>-1.663480</td>\n",
              "      <td>-1.429914</td>\n",
              "      <td>-1.656264</td>\n",
              "      <td>-0.088290</td>\n",
              "      <td>0.838935</td>\n",
              "      <td>0.719063</td>\n",
              "      <td>6.087304</td>\n",
              "      <td>2.273467</td>\n",
              "      <td>-1.240901</td>\n",
              "      <td>0.203448</td>\n",
              "      <td>-0.220629</td>\n",
              "      <td>0.354152</td>\n",
              "      <td>3827.405714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.202329</td>\n",
              "      <td>-0.353193</td>\n",
              "      <td>-0.393739</td>\n",
              "      <td>-0.177161</td>\n",
              "      <td>0.043438</td>\n",
              "      <td>-0.254735</td>\n",
              "      <td>0.175428</td>\n",
              "      <td>0.046602</td>\n",
              "      <td>0.007175</td>\n",
              "      <td>-0.118967</td>\n",
              "      <td>0.026236</td>\n",
              "      <td>-0.002637</td>\n",
              "      <td>0.083223</td>\n",
              "      <td>-0.040509</td>\n",
              "      <td>-0.002165</td>\n",
              "      <td>-0.007867</td>\n",
              "      <td>154.320212</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>1.917827</td>\n",
              "      <td>3.833998</td>\n",
              "      <td>1.668192</td>\n",
              "      <td>0.232463</td>\n",
              "      <td>0.107941</td>\n",
              "      <td>-1.143646</td>\n",
              "      <td>0.541699</td>\n",
              "      <td>0.709148</td>\n",
              "      <td>-2.420716</td>\n",
              "      <td>1.506696</td>\n",
              "      <td>-0.115922</td>\n",
              "      <td>0.015255</td>\n",
              "      <td>0.239994</td>\n",
              "      <td>-0.380576</td>\n",
              "      <td>-0.005823</td>\n",
              "      <td>-0.012105</td>\n",
              "      <td>9.210000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>-0.769172</td>\n",
              "      <td>-0.151513</td>\n",
              "      <td>-0.648374</td>\n",
              "      <td>-1.706658</td>\n",
              "      <td>0.313745</td>\n",
              "      <td>-1.982302</td>\n",
              "      <td>-3.158127</td>\n",
              "      <td>1.247647</td>\n",
              "      <td>-6.393373</td>\n",
              "      <td>-3.258046</td>\n",
              "      <td>-0.102294</td>\n",
              "      <td>-0.036122</td>\n",
              "      <td>-0.753591</td>\n",
              "      <td>0.358493</td>\n",
              "      <td>0.250531</td>\n",
              "      <td>0.250987</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>-1.585505</td>\n",
              "      <td>2.357096</td>\n",
              "      <td>-1.405043</td>\n",
              "      <td>-3.513687</td>\n",
              "      <td>1.515607</td>\n",
              "      <td>-1.207166</td>\n",
              "      <td>-6.234561</td>\n",
              "      <td>1.361193</td>\n",
              "      <td>-6.608068</td>\n",
              "      <td>-2.602478</td>\n",
              "      <td>0.315957</td>\n",
              "      <td>0.501543</td>\n",
              "      <td>-0.546869</td>\n",
              "      <td>-0.425550</td>\n",
              "      <td>0.264028</td>\n",
              "      <td>0.132817</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>-6.003422</td>\n",
              "      <td>1.714669</td>\n",
              "      <td>3.414667</td>\n",
              "      <td>-1.901512</td>\n",
              "      <td>-2.746111</td>\n",
              "      <td>0.887673</td>\n",
              "      <td>-0.049233</td>\n",
              "      <td>-1.894796</td>\n",
              "      <td>-0.831483</td>\n",
              "      <td>1.188907</td>\n",
              "      <td>-4.128186</td>\n",
              "      <td>1.101671</td>\n",
              "      <td>-0.992494</td>\n",
              "      <td>0.139898</td>\n",
              "      <td>1.775378</td>\n",
              "      <td>-0.104285</td>\n",
              "      <td>311.910000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>-3.843009</td>\n",
              "      <td>6.136378</td>\n",
              "      <td>2.797195</td>\n",
              "      <td>-1.668931</td>\n",
              "      <td>-2.617552</td>\n",
              "      <td>-3.945843</td>\n",
              "      <td>-4.565252</td>\n",
              "      <td>-0.965693</td>\n",
              "      <td>-10.904459</td>\n",
              "      <td>-1.139754</td>\n",
              "      <td>0.054796</td>\n",
              "      <td>-1.277812</td>\n",
              "      <td>0.719652</td>\n",
              "      <td>-0.258094</td>\n",
              "      <td>0.739383</td>\n",
              "      <td>-0.203050</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>556 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           V1        V4        V5  ...       V28       Amount  Class\n",
              "0    1.529512  0.459757 -0.104006  ... -0.015416    28.912886      0\n",
              "1   -1.811613  0.523180 -2.822458  ... -0.016139  1267.679388      0\n",
              "2   -0.619164 -0.031784 -0.726452  ...  0.036311   448.502095      0\n",
              "3   -5.675999  2.638208 -6.613113  ...  0.354152  3827.405714      0\n",
              "4    0.202329 -0.353193 -0.393739  ... -0.007867   154.320212      0\n",
              "..        ...       ...       ...  ...       ...          ...    ...\n",
              "551  1.917827  3.833998  1.668192  ... -0.012105     9.210000      1\n",
              "552 -0.769172 -0.151513 -0.648374  ...  0.250987    40.000000      1\n",
              "553 -1.585505  2.357096 -1.405043  ...  0.132817     1.000000      1\n",
              "554 -6.003422  1.714669  3.414667  ... -0.104285   311.910000      1\n",
              "555 -3.843009  6.136378  2.797195  ... -0.203050     1.000000      1\n",
              "\n",
              "[556 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsGkydff4dbO",
        "outputId": "519321f4-31b2-47e5-ae62-ce5f4237cbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "def random_forest_classifier_undersample(test, validation):\n",
        "  x_test = test.loc[:, test.columns != 'Class']\n",
        "  y_test = test[\"Class\"]\n",
        "  x_val = validation.loc[:, validation.columns != 'Class']\n",
        "  y_val = validation[\"Class\"]\n",
        "  model= RandomForestClassifier(n_estimators=500, max_depth=400, max_samples=300)\n",
        "  model.fit(x_test, y_test)\n",
        "\n",
        "  test_prediction = model.predict(x_test)\n",
        "  print(\"training set score \", model.score(x_test, y_test))\n",
        "  f1_score_test = f1_score(y_test, test_prediction)\n",
        "  print(\"F1 training set score \", f1_score_test)\n",
        "  mse_test = mean_squared_error(y_test, test_prediction)\n",
        "  print(\"MSE training set score \", mse_test)\n",
        "\n",
        "\n",
        "  validation_prediction = model.predict(x_val)\n",
        "  print(\"validation set score \", model.score(x_val, y_val))\n",
        "  f1_score_validation = f1_score(y_val, validation_prediction)\n",
        "  print(\"F1 training set score \", f1_score_validation)\n",
        "  mse_validation = mean_squared_error(y_val, validation_prediction)\n",
        "  print(\"MSE training set score \", mse_validation)\n",
        "  return model\n",
        "\n",
        "model_7 = random_forest_classifier_undersample(undersample_random_train_set, validation_set)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.9964028776978417\n",
            "F1 training set score  0.9964028776978417\n",
            "MSE training set score  0.0035971223021582736\n",
            "validation set score  0.6479571299184864\n",
            "F1 training set score  0.009485382600693707\n",
            "MSE training set score  0.3520428700815135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JbR4hno4mDz",
        "outputId": "39a1ae56-201b-486e-f483-3be0c89956f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_8 = svm(undersample_random_train_set, validation_set)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.9622302158273381\n",
            "F1 training set score  0.9610389610389611\n",
            "MSE training set score  0.03776978417266187\n",
            "validation set score  0.9320972124383616\n",
            "F1 training set score  0.04595263343937788\n",
            "MSE training set score  0.06790278756163833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DufgVmF59-2"
      },
      "source": [
        "Undersampling has much worst validation F1 score than the oversampling and the normal dataset result, that is most probabaly because the data sample is much lower which is not helping the model to fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh8c-LyT8lBB"
      },
      "source": [
        "## Testing the Best Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op3--KXp8stn"
      },
      "source": [
        "The best model is the random forest with the normal dataset without oversampling and undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYgQAWNH_DgA",
        "outputId": "2fc6aa45-524a-474b-d0e5-4794933af976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_1 = random_forest_classifier(train_set, validation_set)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score  0.9996980904219186\n",
            "F1 training set score  0.90625\n",
            "MSE training set score  0.0003019095780813646\n",
            "validation set score  0.9994465130321022\n",
            "F1 training set score  0.835820895522388\n",
            "MSE training set score  0.0005534869678977558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww-5AeZ882Tm",
        "outputId": "4de38f48-6141-45d7-80e7-adba99025303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# calculation of the test datset score for the model_1 \n",
        "\n",
        "x_test = test_df.loc[:, test_df.columns != 'Class']\n",
        "y_test = test_df[\"Class\"]\n",
        "\n",
        "test_prediction = model_1.predict(x_test)\n",
        "print(\"Test set score \", model_1.score(x_test, y_test))\n",
        "f1_score_test = f1_score(y_test, test_prediction)\n",
        "print(\"F1 Test set score \", f1_score_test)\n",
        "mse_test = mean_squared_error(y_test, test_prediction)\n",
        "print(\"MSE Test set score \", mse_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score  0.9995201479348805\n",
            "F1 Test set score  0.8240343347639486\n",
            "MSE Test set score  0.00047985206511943633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7mSMmqwArRe"
      },
      "source": [
        "The test score for the model is 82%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbyTZnAH6SRJ",
        "outputId": "90065938-5aaf-40f3-c5fc-4e0e36fa425e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# calculation of the test dataset score for the model_5 random forrest with oversampling of the training set\n",
        "\n",
        "x_test = test_df.loc[:, test_df.columns != 'Class']\n",
        "y_test = test_df[\"Class\"]\n",
        "\n",
        "test_prediction = model_5.predict(x_test)\n",
        "print(\"Test set score \", model_5.score(x_test, y_test))\n",
        "f1_score_test = f1_score(y_test, test_prediction)\n",
        "print(\"F1 Test set score \", f1_score_test)\n",
        "mse_test = mean_squared_error(y_test, test_prediction)\n",
        "print(\"MSE Test set score \", mse_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score  0.999403110845827\n",
            "F1 Test set score  0.8030888030888031\n",
            "MSE Test set score  0.0005968891541729574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDvnaViPB2nY"
      },
      "source": [
        "In this case the test set accuracy is 80% so model_1 with standard dataset is able to generalize better "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htmEKYXBB2Ei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}